#!/bin/bash

MODEL_TYPE="svs"

# ============================================
# å¤šGPUé…ç½® - æ ¹æ®æ‚¨çš„ç¡¬ä»¶ä¿®æ”¹
# ============================================
NUM_GPUS=4  # ä¿®æ”¹ä¸ºæ‚¨çš„GPUæ•°é‡ï¼ˆ2, 4, 8ç­‰ï¼‰
export CUDA_VISIBLE_DEVICES="0,1,2,3"  # ä¿®æ”¹ä¸ºæ‚¨è¦ä½¿ç”¨çš„GPU ID

# ============================================
# è®­ç»ƒå‚æ•°
# ============================================
MAX_EPOCH=50
MODEL_NAME_OR_MODEL_DIR="/code/FunASR/models/svs"

TRAIN_DATA="/asr-corpus/train/teochew/convert_5th/train.jsonl"
VAL_DATA="/asr-corpus/train/teochew/convert_5th/val.jsonl"
OUTPUT_DIR="/traindata/outputs/mixed/svs-teo-aggressive-v4-multigpu"
MASTER_PORT=57329

# ============================================
# Batch Size å’Œå­¦ä¹ ç‡é…ç½®
# ============================================
# å•å¡é…ç½®
BATCH_SIZE_PER_GPU=60000  # æ¯å¼ å¡çš„batch size
NUM_WORKERS=8

# å¤šå¡é…ç½® - è‡ªåŠ¨è®¡ç®—
EFFECTIVE_BATCH_SIZE=$((BATCH_SIZE_PER_GPU * NUM_GPUS))
BASE_LR=0.00005

# å­¦ä¹ ç‡ç¼©æ”¾ç­–ç•¥ï¼ˆä½¿ç”¨Pythonè®¡ç®—ï¼Œé¿å…bcä¾èµ–ï¼‰
# é€‰é¡¹1: å¹³æ–¹æ ¹ç¼©æ”¾ï¼ˆæ¨èï¼Œæ›´ä¿å®ˆï¼‰
SCALED_LR=$(python3 -c "import math; print($BASE_LR * math.sqrt($NUM_GPUS))")

# é€‰é¡¹2: çº¿æ€§ç¼©æ”¾ï¼ˆå¦‚éœ€ä½¿ç”¨ï¼Œæ³¨é‡Šæ‰ä¸Šé¢ä¸€è¡Œï¼Œå–æ¶ˆæ³¨é‡Šä¸‹é¢ä¸€è¡Œï¼‰
# SCALED_LR=$(python3 -c "print($BASE_LR * $NUM_GPUS)")

# é€‰é¡¹3: ä¸ç¼©æ”¾ï¼ˆå¦‚éœ€ä½¿ç”¨ï¼Œæ³¨é‡Šæ‰ä¸Šé¢çš„SCALED_LRè¡Œï¼Œå–æ¶ˆæ³¨é‡Šä¸‹é¢ä¸€è¡Œï¼‰
# SCALED_LR=$BASE_LR

# ============================================
# åˆ†å¸ƒå¼è®­ç»ƒé…ç½®
# ============================================
GPU_NUM=${NUM_GPUS}
LOG_FILE="${OUTPUT_DIR}/log.txt"

mkdir -p ${OUTPUT_DIR}

DISTRIBUTED_ARGS="
    --nnodes 1 \
    --nproc_per_node ${NUM_GPUS} \
    --master_addr 127.0.0.1 \
    --master_port ${MASTER_PORT}
"

TRAIN_TOOL="/code/FunASR/funasr/bin/train_ds.py"

# ============================================
# å¯åŠ¨TensorBoard
# ============================================
pkill -f "tensorboard"
rm -rf "${OUTPUT_DIR}/tb.log"
nohup bash -c "sleep 15 && tensorboard --host=0.0.0.0 --logdir='${OUTPUT_DIR}/tensorboard/'" > "${OUTPUT_DIR}/tb.log" 2>&1 &

# ============================================
# å¼€å§‹è®­ç»ƒ
# ============================================
if [ "$MODEL_TYPE" = "svs" ]; then
    torchrun $DISTRIBUTED_ARGS \
    ${TRAIN_TOOL} \
    ++model="${MODEL_NAME_OR_MODEL_DIR}" \
    ++disable_update=True \
    ++train_data_set_list="${TRAIN_DATA}" \
    ++valid_data_set_list="${VAL_DATA}" \
    \
    ++dataset_conf.data_split_num=1 \
    ++dataset_conf.batch_sampler="BatchSampler" \
    ++dataset_conf.batch_type="token" \
    ++dataset_conf.batch_size=${BATCH_SIZE_PER_GPU} \
    ++dataset_conf.sort_size=1024 \
    ++dataset_conf.min_token_length=300 \
    ++dataset_conf.max_token_length=4000 \
    ++dataset_conf.num_workers=${NUM_WORKERS} \
    ++dataset_conf.shuffle=true \
    \
    ++train_conf.max_epoch=${MAX_EPOCH} \
    ++train_conf.log_interval=50 \
    ++train_conf.resume=true \
    ++train_conf.validate_interval=1000 \
    ++train_conf.save_checkpoint_interval=1000 \
    ++train_conf.keep_nbest_models=40 \
    ++train_conf.avg_nbest_model=30 \
    ++train_conf.avg_keep_nbest_models_type="acc" \
    ++train_conf.grad_clip=5.0 \
    ++train_conf.accum_grad=1 \
    ++train_conf.early_stopping_patience=10 \
    ++train_conf.use_deepspeed=false \
    \
    ++optim="adam" \
    ++optim_conf.lr=${SCALED_LR} \
    ++optim_conf.weight_decay=0.0 \
    \
    ++scheduler="warmuplr" \
    ++scheduler_conf.warmup_steps=2000 \
    \
    ++output_dir="${OUTPUT_DIR}" &> ${LOG_FILE} &
    
    echo "âœ… Multi-GPU Training started!"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "ğŸ¯ Configuration:"
    echo "  - Number of GPUs: ${NUM_GPUS}"
    echo "  - GPU IDs: ${CUDA_VISIBLE_DEVICES}"
    echo "  - Batch size per GPU: ${BATCH_SIZE_PER_GPU} tokens"
    echo "  - Effective batch size: ${EFFECTIVE_BATCH_SIZE} tokens"
    echo "  - Base learning rate: ${BASE_LR}"
    echo "  - Scaled learning rate: ${SCALED_LR}"
    echo "  - Model averaging: 30 best models"
    echo "  - Keep best: 40 models"
    echo ""
    echo "ğŸ“Š Monitoring:"
    echo "  - Log file: tail -f ${LOG_FILE}"
    echo "  - TensorBoard: http://0.0.0.0:6006"
    echo ""
    echo "ğŸ’¡ Tips:"
    echo "  - Monitor GPU usage: watch -n 1 nvidia-smi"
    echo "  - Check training progress: grep 'loss' ${LOG_FILE}"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
fi
